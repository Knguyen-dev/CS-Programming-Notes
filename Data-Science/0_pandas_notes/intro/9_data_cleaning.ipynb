{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning \n",
    "In most of the data that you'll be dealing with you're going to have some issues with the data itself. Things such as NaN or some other kind of invalid value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame({\n",
    "    'first': ['Corey', 'Jane', 'John', 'Chris', np.nan, None, 'NA'], \n",
    "    'last': ['Schafer', 'Doe', 'Doe', 'Schafer', np.nan, np.nan, 'Missing'], \n",
    "    'email': ['CoreyMSchafer@gmail.com', 'JaneDoe@email.com', 'JohnDoe@email.com', None, np.nan, 'Anonymous@email.com', 'NA'],\n",
    "    'age': ['33', '55', '63', '36', None, None, 'Missing']\n",
    "})\n",
    "\n",
    "'''\n",
    "1. Drop all rows with missing values, so if ; do reassignment if you want to apply these changes of course\n",
    "\n",
    "Default behavior: df.dropna(axis=\"index\", how=\"any\")\n",
    "So 'index' means to drop a ROWS if they had ANY missing values (NaN).\n",
    "'''\n",
    "df.dropna()\n",
    "\n",
    "'''\n",
    "2. Maybe missing some values is alright, but if all values are missing then \n",
    "drop the rows.\n",
    "'''\n",
    "df.dropna(axis=\"index\" how=\"all\")\n",
    "\n",
    "\n",
    "'''\n",
    "3. Let's say we don't care about missing the first or last name, but\n",
    "if it's missing the email address, then we need to drop the row. \n",
    "'''\n",
    "df.dropna(axis='index', subset=['email'])\n",
    "\n",
    "'''\n",
    "4. We need the last name or the email. We just need one of them. So this will \n",
    "  read: \"Drop the row of ALL of the values in subset are missing\". So if email and \n",
    "  last name don't exist, then drop the row. If at least one of them exist then keep the row.\n",
    "\n",
    "NOTE: Remember that this returns a result data frame, and to actually apply these drop changes, you \n",
    "have to do inplace=True or reassignment.\n",
    "'''\n",
    "df.dropna(axis='index', subset=['email', 'last'])\n",
    "\n",
    "'''\n",
    "5. Let's say people didn't know what to do and entered 'MISSING' or 'N/A' instead of leaving things blank.\n",
    "So to deal with this, we'll use numpy, and convert those custom missing values into a proper NaN. Then \n",
    "you can proceed with data processing like normal.\n",
    "'''\n",
    "df.replace(\"NA\", np.nan, inplace=True)\n",
    "df.replace(\"MISSING\", np.nan, inplace=True)\n",
    "\n",
    "'''\n",
    "6. Gives us a mask or table of booleans, indicating whether something \n",
    "is NaN or not.\n",
    "'''\n",
    "df.isna()\n",
    "\n",
    "'''\n",
    "7. Let's say a student has an assignment 'NaN' for missing assignment. We want to make \n",
    "it so all NaN values would be replaced with the number '0' for their score on the assignment.\n",
    "\n",
    "Replaces all NA values with 0 string.\n",
    "'''\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "'''\n",
    "8. NaN values are actually represented as floats under the hood.\n",
    "You can't convert NaN into integer, but the solution is to have everything as float. So convert all of the values in the age series \n",
    "into floats.\n",
    "'''\n",
    "df['age'] = df['age'].astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(11.662114216834588)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "+ Analysis on Stackoverflow data\n",
    "1. This is more appropriate for the last dataset, but if we had custom 'missing' values such as 'NA' and 'Missing'. Then by passing in this \n",
    "array, when the CSV loads in, it'll convert any cell with 'NA' or 'Missing' into a numpy NaN.\n",
    "\n",
    "2. Let's try to find the average years a person has been coding. We can do 'YearsCode', however we'll get an error  'can only concatenate str (not 'int') to str'.\n",
    "This is trying to tell us that the values in YearsCode are strings. So like do 'df[\"YearsCode\"].apply(lambda x: type(x))' to see that the 'numbers' are actually strings, \n",
    "whilst the NaN are floats (which we talked about before). A simple trick is to convert all of these values into floats.\n",
    "However this will also have issues as we'll have values in the series such as 'Less than 1 year'. First let's see all of the possible unique values in this YearsCode column\n",
    "\n",
    "3. Replace 'Less than 1 year' with 0. Then replace 'More than 50 years', probably with the value of 51 for a good estimate. Now we should be able to convert \n",
    "everything to a float.\n",
    "\n",
    "4. Now get the mean of the 'YearsCode' column\n",
    "'''\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "csvPath = \"../data/survey_results_public.csv\"\n",
    "na_values = ['NA','Missing']\n",
    "\n",
    "# 2\n",
    "df = pd.read_csv(csvPath, index_col=\"Respondent\", na_values=na_values)\n",
    "df[\"YearsCode\"].unique()\n",
    "\n",
    "\n",
    "# 3\n",
    "df[\"YearsCode\"] = df[\"YearsCode\"].replace({\"Less than 1 year\": 0, \"More than 50 years\": 51})\n",
    "df[\"YearsCode\"] = df[\"YearsCode\"].astype(float)\n",
    "\n",
    "# 4\n",
    "df[\"YearsCode\"].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
